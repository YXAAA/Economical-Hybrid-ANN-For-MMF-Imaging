{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 先说恢复误删单元格的操作\n",
    "# 场景：不小心把某个cell给cut了，或者删除了单元格（前提不要关闭notebook窗口）。\n",
    "\n",
    "# 解决方法： 先按Esc键进入命令模式，在按z键就会恢复。记住不要按Ctrl+z（这个只限没删除单元格的常规操作）\n",
    "\n",
    "# 命令模式和编辑模式识别：\n",
    "# 命令模式：左侧为蓝色。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#我们现在应该在master上弃用torch.nn.functional.tanh，因为现在已经合并了张量和变量。\n",
    "#If you deprecate nn.functional.tanh I could do\n",
    "# output = nn.Tanh()(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py  #导入工具包\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import autograd\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import math\n",
    "import h5py  #导入工具包\n",
    "import os\n",
    "from PIL import Image,ImageFilter\n",
    "import matplotlib.pyplot as plt # plt 用于显示图片\n",
    "import matplotlib.image as mpimg # mpimg 用于读取图片\n",
    "\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.nn import init\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#注意！！！sample像素值属于0-255，labels 像素值属于0-1  sample需要归一化\n",
    "#torch.from_numpy是相同引用\n",
    "#torch.tensor(...)应该是新建！！！！！！！\n",
    "import h5py  #导入工具包\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "from PIL import Image,ImageFilter\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "smallSampleFile =r\"/root/code/DataSet30000.h5\"\n",
    "smallDataSet = h5py.File(smallSampleFile,'r') \n",
    "samples = np.array(smallDataSet['samples'])\n",
    "samples = samples/255  #进行归一化\n",
    "labels = np.array(smallDataSet['labels'])\n",
    "smallDataSet.close()\n",
    "\n",
    "samples = torch.from_numpy(samples)\n",
    "labels = torch.from_numpy(labels)\n",
    "print(samples.shape,samples.dtype)\n",
    "print(labels.shape,labels.dtype)\n",
    "\n",
    "testFile = r\"/root/code/DataSet500.h5\"\n",
    "testSet = h5py.File(testFile,'r') \n",
    "testSamples= np.array(testSet['samples'])\n",
    "testSamples = testSamples/255  #进行归一化\n",
    "testLabels = np.array(testSet['labels'])\n",
    "testSet.close()\n",
    "\n",
    "testSamples = torch.from_numpy(testSamples)\n",
    "testLabels = torch.from_numpy(testLabels)\n",
    "\n",
    "print(testSamples.shape,samples.dtype)\n",
    "print(testLabels.shape,labels.dtype)\n",
    "\n",
    "print(samples.shape)\n",
    "print(labels.shape)\n",
    "print(testSamples.shape)\n",
    "print(testLabels.shape)\n",
    "print(samples.dtype)\n",
    "print(labels.dtype)\n",
    "print(testSamples.dtype)\n",
    "print(testLabels.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt # plt 用于显示图片\n",
    "import matplotlib.image as mpimg # mpimg 用于读取图片\n",
    "def show_original_and_speckle(index):\n",
    "    plt.figure()\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(samples[index][0].cpu(),cmap='gray')\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(labels[index][0].cpu(),cmap='gray')\n",
    "    plt.show()\n",
    "def show_test_original_and_speckle(index):\n",
    "    plt.figure()\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(testSamples[index][0].cpu(),cmap='gray')\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(testLabels[index][0].cpu(),cmap='gray')\n",
    "    plt.show()\n",
    "index=10\n",
    "show_test_original_and_speckle(index)\n",
    "#very good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#创建子类\n",
    "import torch.utils.data.dataloader as DataLoader\n",
    "import torch.utils.data.dataset as Dataset\n",
    "class subDataset(Dataset.Dataset):    \n",
    "    #初始化，定义数据内容和标签\n",
    "    def __init__(self, Data, Label,W,device):\n",
    "        self.Data = Data\n",
    "        self.Label = Label\n",
    "     #   self.XY = PositionXYGenerator(W,device)\n",
    "    #返回数据集大小\n",
    "    def __len__(self):\n",
    "        return len(self.Data)\n",
    "    #得到数据内容和标签\n",
    "    def __getitem__(self, index):\n",
    "        data = self.Data[index].to(device)\n",
    "     #   data = torch.cat((self.XY,data),0)\n",
    "        label = self.Label[index].to(device)\n",
    "#         data = data.view(data.shape[0],data.shape[1]*data.shape[2])\n",
    "#         label = label.view(label.shape[0],label.shape[1]*label.shape[2])\n",
    "        return data, label\n",
    "    \n",
    "dataset = subDataset(samples,labels,120,device)\n",
    "\n",
    "\n",
    "device_count = 1\n",
    "if(torch.cuda.device_count()>1):\n",
    "    device_count = torch.cuda.device_count()\n",
    "batchSize = 16*device_count\n",
    "\n",
    "\n",
    "print(\"batchSize:\",batchSize)\n",
    "dataloader = DataLoader.DataLoader(dataset,batch_size= batchSize, shuffle = True)\n",
    "# print(dataset.Data[10])\n",
    "# print(dataset.Label.shape)\n",
    "# print(labels)\n",
    "print(dataset.__getitem__(10)[0].shape,dataset.__getitem__(10)[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#单一全连接 单一通道  存在前conv 无后conv\n",
    "class Transmission_Matrix(nn.Module):\n",
    "    def __init__(self,Win,Wout):  #batchsize * channelnum * W * W,  \n",
    "        super(Transmission_Matrix, self).__init__()\n",
    "        self.Matrix = nn.Linear(Win*Win, Wout*Wout, bias=True)\n",
    "        self.Win = Win\n",
    "        self.Wout = Wout\n",
    "    def forward(self, input):\n",
    "        W = input.shape[2]\n",
    "        input = input.view(input.shape[0],input.shape[1],self.Win*self.Win)\n",
    "        out = self.Matrix(input)\n",
    "        out = out.view(input.shape[0],input.shape[1],self.Wout,self.Wout)\n",
    "        return out\n",
    "    \n",
    "class EnhancedNet(nn.Module):\n",
    "    def __init__(self,Win,Wout,Temp_feature_nums):\n",
    "        super(EnhancedNet, self).__init__()\n",
    "        self.head=nn.Sequential(\n",
    "            nn.Conv2d(1,Temp_feature_nums,3,padding=3//2),\n",
    "            nn.Tanh(),\n",
    "            nn.Conv2d(Temp_feature_nums,Temp_feature_nums,3, padding=3//2),\n",
    "            nn.Tanh(),\n",
    "#             nn.Conv2d(Temp_feature_nums,Temp_feature_nums,3, padding=3//2),\n",
    "#             nn.LeakyReLU(True),\n",
    "            nn.Conv2d(Temp_feature_nums,1,3, padding=3//2),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        self.Matrix_r = Transmission_Matrix(Win,Wout)\n",
    "        self.tailAct=nn.Sigmoid()\n",
    "        \n",
    "    def forward(self,input):\n",
    "\n",
    "        result = self.tailAct(self.Matrix_r(self.head(input)))\n",
    "        return result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "net = EnhancedNet(Win=120,Wout=92,Temp_feature_nums=64)\n",
    "if torch.cuda.device_count() > 1:\n",
    "  print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "  # dim = 0 [30, xxx] -> [10, ...], [10, ...], [10, ...] on 3 GPUs\n",
    "  net = nn.DataParallel(net)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#showTestResult_XY = PositionXYGenerator(120,device)\n",
    "def showTestResult(net,testSamples,testLabels,index):\n",
    "    \n",
    "    net.train(False)\n",
    "    _sample = testSamples[index].to(device)\n",
    "    with torch.no_grad():\n",
    "        output = net(_sample.view(1,1,120,120))\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.subplot(131)\n",
    "    plt.title(\"speckle\")\n",
    "    plt.imshow(testSamples[index][0].cpu(),cmap='gray')\n",
    "    # plt.show()#show不需要写啦！！\n",
    "\n",
    "    plt.subplot(132)\n",
    "    plt.title(\"output\")\n",
    "    img = output[0][0].cpu().numpy()\n",
    "    np.where(img > 0, img, 0)\n",
    "    plt.imshow(output[0][0].cpu(),cmap='gray')\n",
    "\n",
    "    plt.subplot(133)\n",
    "    plt.title(\"real label\")\n",
    "    img_t = testLabels[index][0].cpu().numpy()\n",
    "    np.where(img_t > 0, img_t, 0)\n",
    "    plt.imshow(testLabels[index][0].cpu(),cmap='gray')\n",
    "    plt.show()\n",
    "    net.train(True)\n",
    "index = 8\n",
    "showTestResult(net,testSamples,testLabels,index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "#optimizer = optim.SGD(net.parameters(), lr=0.00001, momentum=0.9)\n",
    "optimizer = optim.Adam(net.parameters(), lr=8e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "startTime = time.time()\n",
    "net.train(True)\n",
    "for epoch in range(100):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = torch.dist(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        #testReconstruction\n",
    "        running_loss += loss.item()\n",
    "#         if i %100 ==99:    # print every 2000 mini-batches\n",
    "#             print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 200))\n",
    "#             running_loss = 0.0\n",
    "        if i %100==99:    # print every 2000 mini-batches\n",
    "            ticks = time.time()-startTime\n",
    "            print(\"当前时间戳为:\", ticks)\n",
    "            print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 100))\n",
    "            running_loss = 0.0\n",
    "            index = 10\n",
    "            showTestResult(net,testSamples,testLabels,index)\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,50):\n",
    "    showTestResult(net,testSamples,testLabels,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save\n",
    "import matplotlib.pyplot as plt # plt 用于显示图片\n",
    "import matplotlib.image as mpimg # mpimg 用于读取图片\n",
    "    \n",
    "def SaveResult(net,testSamples,testLabels,index,device,root_path,windows_or_linux='\\\\'):   \n",
    "    \n",
    "    net.train(False)\n",
    "    _sample = testSamples[index].to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = net(_sample.view(1,1,120,120))\n",
    "\n",
    "    mpimg.imsave(root_path+windows_or_linux+str(index)+'_speckle'+'.png',testSamples[index][0].cpu().numpy(),cmap='gray')\n",
    "    mpimg.imsave(root_path+windows_or_linux+str(index)+'_reconstruction'+'.png',output[0][0].cpu().numpy(),cmap='gray')\n",
    "    mpimg.imsave(root_path+windows_or_linux+str(index)+'_realLabel'+'.png',testLabels[index][0].cpu().numpy(),cmap='gray')\n",
    "    net.train(True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PSNR.py\n",
    "import numpy as np\n",
    "import math\n",
    " \n",
    "def psnr(target, ref):\n",
    "    # target:目标图像  ref:参考图像  scale:尺寸大小\n",
    "    # assume RGB image\n",
    "    target_data = np.array(target)\n",
    "\n",
    "    ref_data = np.array(ref)\n",
    "\n",
    "    diff = ref_data - target_data\n",
    "    diff = diff.flatten('C')\n",
    "    rmse = math.sqrt( np.mean(diff ** 2.) )\n",
    "    scale=1.0\n",
    "    return 20*math.log10(scale/rmse)\n",
    "\n",
    "import matplotlib.pyplot as plt # plt 用于显示图片\n",
    "import matplotlib.image as mpimg # mpimg 用于读取图片\n",
    "    \n",
    "def set_psnr(net,testSamples,testLabels,index,device):   \n",
    "    \n",
    "    net.train(False)\n",
    "    _sample = testSamples[index].to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = net(_sample.view(1,1,120,120))\n",
    "    \n",
    "    output = psnr(output[0][0].cpu().numpy(),testLabels[index][0].cpu().numpy())\n",
    "    net.train(True)\n",
    "    return output\n",
    "\n",
    "sum_psnr=0\n",
    "for i in range(500):\n",
    "    sum_psnr=sum_psnr+set_psnr(net,testSamples,testLabels,i,device)\n",
    "print(sum_psnr/500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from math import exp\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "# 计算一维的高斯分布向量\n",
    "def gaussian(window_size, sigma):\n",
    "    gauss = torch.Tensor([exp(-(x - window_size//2)**2/float(2*sigma**2)) for x in range(window_size)])\n",
    "    return gauss/gauss.sum()\n",
    "\n",
    "# 创建高斯核，通过两个一维高斯分布向量进行矩阵乘法得到\n",
    "# 可以设定channel参数拓展为3通道\n",
    "def create_window(window_size, channel=1):\n",
    "    _1D_window = gaussian(window_size, 1.5).unsqueeze(1)\n",
    "    _2D_window = _1D_window.mm(_1D_window.t()).float().unsqueeze(0).unsqueeze(0)\n",
    "    window = _2D_window.expand(channel, 1, window_size, window_size).contiguous()\n",
    "    return window\n",
    " \n",
    "# 计算SSIM\n",
    "# 直接使用SSIM的公式，但是在计算均值时，不是直接求像素平均值，而是采用归一化的高斯核卷积来代替。\n",
    "# 在计算方差和协方差时用到了公式Var(X)=E[X^2]-E[X]^2, cov(X,Y)=E[XY]-E[X]E[Y].\n",
    "# 正如前面提到的，上面求期望的操作采用高斯核卷积代替。\n",
    "def ssim(img1, img2, window_size=11, window=None, size_average=True, full=False, val_range=1):\n",
    "    # Value range can be different from 255. Other common ranges are 1 (sigmoid) and 2 (tanh).\n",
    "    if val_range is None:\n",
    "        if torch.max(img1) > 128:\n",
    "            max_val = 255\n",
    "        else:\n",
    "            max_val = 1\n",
    " \n",
    "        if torch.min(img1) < -0.5:\n",
    "            min_val = -1\n",
    "        else:\n",
    "            min_val = 0\n",
    "        L = max_val - min_val\n",
    "    else:\n",
    "        L = val_range\n",
    " \n",
    "    padd = 0\n",
    "    (_, channel, height, width) = img1.size()\n",
    "    if window is None:\n",
    "        real_size = min(window_size, height, width)\n",
    "        window = create_window(real_size, channel=channel).to(img1.device)\n",
    " \n",
    "    mu1 = F.conv2d(img1, window, padding=padd, groups=channel)\n",
    "    mu2 = F.conv2d(img2, window, padding=padd, groups=channel)\n",
    " \n",
    "    mu1_sq = mu1.pow(2)\n",
    "    mu2_sq = mu2.pow(2)\n",
    "    mu1_mu2 = mu1 * mu2\n",
    " \n",
    "    sigma1_sq = F.conv2d(img1 * img1, window, padding=padd, groups=channel) - mu1_sq\n",
    "    sigma2_sq = F.conv2d(img2 * img2, window, padding=padd, groups=channel) - mu2_sq\n",
    "    sigma12 = F.conv2d(img1 * img2, window, padding=padd, groups=channel) - mu1_mu2\n",
    " \n",
    "    C1 = (0.01 * L) ** 2\n",
    "    C2 = (0.03 * L) ** 2\n",
    " \n",
    "    v1 = 2.0 * sigma12 + C2\n",
    "    v2 = sigma1_sq + sigma2_sq + C2\n",
    "    cs = torch.mean(v1 / v2)  # contrast sensitivity\n",
    " \n",
    "    ssim_map = ((2 * mu1_mu2 + C1) * v1) / ((mu1_sq + mu2_sq + C1) * v2)\n",
    " \n",
    "    if size_average:\n",
    "        ret = ssim_map.mean()\n",
    "    else:\n",
    "        ret = ssim_map.mean(1).mean(1).mean(1)\n",
    " \n",
    "    if full:\n",
    "        return ret, cs\n",
    "    return ret\n",
    " \n",
    "# Classes to re-use window\n",
    "class SSIM(torch.nn.Module):\n",
    "    def __init__(self, window_size=11, size_average=True, val_range=None):\n",
    "        super(SSIM, self).__init__()\n",
    "        self.window_size = window_size\n",
    "        self.size_average = size_average\n",
    "        self.val_range = val_range\n",
    " \n",
    "        # Assume 1 channel for SSIM\n",
    "        self.channel = 1\n",
    "        self.window = create_window(window_size)\n",
    " \n",
    "    def forward(self, img1, img2):\n",
    "        (_, channel, _, _) = img1.size()\n",
    " \n",
    "        if channel == self.channel and self.window.dtype == img1.dtype:\n",
    "            window = self.window\n",
    "        else:\n",
    "            window = create_window(self.window_size, channel).to(img1.device).type(img1.dtype)\n",
    "            self.window = window\n",
    "            self.channel = channel\n",
    " \n",
    "        return ssim(img1 ,img2 ,window_size=self.window_size ,window=self.window ,size_average=self.size_average ,val_range=self.val_range)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssim_class=SSIM(val_range=1)\n",
    "print(\"creat ssim\")\n",
    "def ssim_calculate(ssim_class,image1,image2):\n",
    "    with torch.no_grad():\n",
    "        result=ssim_class(image1,image2)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#通过一个网络和散斑重建，并和Label计算SSIM\n",
    "def netAndOriginalAndLabel_to_ssim(net,W1,W2,testSamples,testLabels,index,device):   \n",
    "    net.train(False)\n",
    "    _sample = (testSamples[index].view(1,1,W1,W1)).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = net(_sample)\n",
    "\n",
    "    output = ssim_calculate(ssim_class,output.cpu(),(testLabels[index].view(1,1,W2,W2))).numpy()\n",
    "    net.train(True)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(netAndOriginalAndLabel_to_ssim(net,120,92,testSamples,testLabels,15,device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#计算平均SSIM\n",
    "sum_ssim=0\n",
    "for i in range(500):\n",
    "    sum_ssim=sum_ssim+netAndOriginalAndLabel_to_ssim(net,120,92,testSamples,testLabels,i,device)\n",
    "print(sum_ssim/500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#将测试集的散斑图片、原图像和重建图像 以及将对应的名称的PSNR和SSIM保存到list中。\n",
    "SimulationSystemResult_PSNR_SSIM=[]\n",
    "average_psnr=0\n",
    "average_ssim=0\n",
    "with open( '/root/code/result_of_realSystem_ours.txt', 'w' ) as f:\n",
    "    for i in range(500):\n",
    "        SaveResult(net,testSamples,testLabels,i,device,root_path=r'/root/code/realSystem_ours_result',windows_or_linux='//')  \n",
    "        \n",
    "        singe_psnr = set_psnr(net,testSamples,testLabels,i,device)\n",
    "        average_psnr=average_psnr+singe_psnr\n",
    "        \n",
    "        singe_ssim = netAndOriginalAndLabel_to_ssim(net,120,92,testSamples,testLabels,i,device)\n",
    "        average_ssim = average_ssim + singe_ssim\n",
    "        \n",
    "        s=\"result_\"+str(i)+\"psnr_and_ssim\"\n",
    "        SimulationSystemResult_PSNR_SSIM.append((s,singe_psnr,singe_ssim))\n",
    "        f.writelines(s+' '+str(singe_psnr)+' '+str(singe_ssim)+'\\n')\n",
    "        print((s,singe_psnr,singe_ssim))\n",
    "print(average_psnr/500,average_ssim/500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "def zip_ya():\n",
    "    startdir = r'/root/code/realSystem_ours_result'  #要压缩的文件夹路径\n",
    "    file_news = startdir +'.zip' # 压缩后文件夹的名字\n",
    "    z = zipfile.ZipFile(file_news,'w',zipfile.ZIP_DEFLATED) #参数一：文件夹名\n",
    "    for dirpath, dirnames, filenames in os.walk(startdir):\n",
    "        fpath = dirpath.replace(startdir,'') #这一句很重要，不replace的话，就从根目录开始复制\n",
    "        fpath = fpath and fpath + os.sep or ''#这句话理解我也点郁闷，实现当前文件夹以及包含的所有文件的压缩\n",
    "        for filename in filenames:\n",
    "            z.write(os.path.join(dirpath, filename),fpath+filename)\n",
    "            print ('压缩成功')\n",
    "    z.close()\n",
    "zip_ya()\n",
    "# if__name__==\"__main__\"\n",
    "#     startdir = \".\\\\123\"  #要压缩的文件夹路径\n",
    "#     file_news = startdir +'.zip' # 压缩后文件夹的名字 \n",
    "#     zip_ya(startdir，file_news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#前向传播时间计算：\n",
    "_sample = testSamples[index].to(device).view(1,1,120,120)\n",
    "startTime = time.time()\n",
    "with torch.no_grad():\n",
    "    for i in range(10000):\n",
    "        output = net(_sample)\n",
    "    inferenceTime_s =(time.time()-startTime)\n",
    "    print(10000/inferenceTime_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#模型大小计算\n",
    "torch.save(net, 'OurNet.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
